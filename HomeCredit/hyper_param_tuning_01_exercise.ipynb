{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyper_param_tuning_01_exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1c5000/kaggle/blob/main/HomeCredit/hyper_param_tuning_01_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEHCvFhIvR4F"
      },
      "source": [
        "### Bayesian Optimization을 이용하여 application과 previous로 만들어진 집합의 하이퍼 파라미터 튜닝\r\n",
        "핵심적인 몇가지 파라미터만 접근하여 튜닝하는것이 성능에 더 도움이 된다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg1AO0nNvR4H"
      },
      "source": [
        "#### 라이브러리 및 데이터 세트 로딩. 이전 application 데이터의 FE 함수 복사"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il0VyvcgvR4K"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIJ5-Lu-wbya"
      },
      "source": [
        "##### 코랩 버전은 Google Drive에서 데이터 세트를 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHiS9-DqwUk_"
      },
      "source": [
        "import os, sys \n",
        "# from google.colab import drive \n",
        "\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "0fFr8p7un8PW",
        "outputId": "a11ff1aa-91a0-4e26-9450-00010995048a"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()\r\n",
        "\r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "# Permission Warning 이 일어나지 않도록 \r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e3c71a46-6e59-48a7-af28-54b1761b9548\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e3c71a46-6e59-48a7-af28-54b1761b9548\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8HoYEr8n9US",
        "outputId": "eb2d033a-1193-482e-b2d4-ebb89e28baf6"
      },
      "source": [
        "!kaggle competitions download -c home-credit-default-risk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading POS_CASH_balance.csv.zip to /content\n",
            " 80% 87.0M/109M [00:00<00:00, 96.2MB/s]\n",
            "100% 109M/109M [00:00<00:00, 124MB/s]  \n",
            "Downloading application_test.csv.zip to /content\n",
            "  0% 0.00/5.81M [00:00<?, ?B/s]\n",
            "100% 5.81M/5.81M [00:00<00:00, 53.3MB/s]\n",
            "Downloading previous_application.csv.zip to /content\n",
            " 76% 58.0M/76.3M [00:00<00:00, 81.8MB/s]\n",
            "100% 76.3M/76.3M [00:00<00:00, 109MB/s] \n",
            "Downloading credit_card_balance.csv.zip to /content\n",
            " 98% 95.0M/96.7M [00:00<00:00, 87.2MB/s]\n",
            "100% 96.7M/96.7M [00:01<00:00, 98.3MB/s]\n",
            "Downloading HomeCredit_columns_description.csv to /content\n",
            "  0% 0.00/36.5k [00:00<?, ?B/s]\n",
            "100% 36.5k/36.5k [00:00<00:00, 70.2MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/524k [00:00<?, ?B/s]\n",
            "100% 524k/524k [00:00<00:00, 69.4MB/s]\n",
            "Downloading bureau.csv.zip to /content\n",
            " 79% 29.0M/36.8M [00:00<00:00, 54.0MB/s]\n",
            "100% 36.8M/36.8M [00:00<00:00, 92.9MB/s]\n",
            "Downloading installments_payments.csv.zip to /content\n",
            " 98% 265M/271M [00:02<00:00, 122MB/s]\n",
            "100% 271M/271M [00:02<00:00, 121MB/s]\n",
            "Downloading application_train.csv.zip to /content\n",
            " 94% 34.0M/36.1M [00:00<00:00, 77.4MB/s]\n",
            "100% 36.1M/36.1M [00:00<00:00, 81.3MB/s]\n",
            "Downloading bureau_balance.csv.zip to /content\n",
            "100% 56.8M/56.8M [00:00<00:00, 114MB/s] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAQRjc1pn9fo",
        "outputId": "7e51b898-009d-4934-ed2b-0f2fd8e2a4d0"
      },
      "source": [
        "!unzip '/content/application_train.csv.zip'\r\n",
        "!unzip '/content/application_test.csv.zip'\r\n",
        "!unzip '/content/previous_application.csv.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/application_train.csv.zip\n",
            "  inflating: application_train.csv   \n",
            "Archive:  /content/application_test.csv.zip\n",
            "  inflating: application_test.csv    \n",
            "Archive:  /content/previous_application.csv.zip\n",
            "  inflating: previous_application.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaO4thuSvR4X"
      },
      "source": [
        "def get_dataset():\n",
        "    #default_dir = \"/content/gdrive/My Drive\"\n",
        "    default_dir = \"/content\"\n",
        "    app_train = pd.read_csv(os.path.join(default_dir, 'application_train.csv'))\n",
        "    app_test = pd.read_csv(os.path.join(default_dir, 'application_test.csv'))\n",
        "    apps = pd.concat([app_train, app_test])\n",
        "    prev = pd.read_csv(os.path.join(default_dir, 'previous_application.csv'))\n",
        "\n",
        "    return apps, prev\n",
        "\n",
        "apps, prev = get_dataset()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmG4YOdpvR4e"
      },
      "source": [
        "#### 이전 application 데이터의 feature engineering 함수 복사"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WIrIw4uvR4h"
      },
      "source": [
        "def get_apps_processed(apps):\n",
        "    \n",
        "    # EXT_SOURCE_X FEATURE 가공\n",
        "    apps['APPS_EXT_SOURCE_MEAN'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
        "    apps['APPS_EXT_SOURCE_STD'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
        "    apps['APPS_EXT_SOURCE_STD'] = apps['APPS_EXT_SOURCE_STD'].fillna(apps['APPS_EXT_SOURCE_STD'].mean())\n",
        "    \n",
        "    # AMT_CREDIT 비율로 Feature 가공\n",
        "    apps['APPS_ANNUITY_CREDIT_RATIO'] = apps['AMT_ANNUITY']/apps['AMT_CREDIT']\n",
        "    apps['APPS_GOODS_CREDIT_RATIO'] = apps['AMT_GOODS_PRICE']/apps['AMT_CREDIT']\n",
        "    \n",
        "    # AMT_INCOME_TOTAL 비율로 Feature 가공\n",
        "    apps['APPS_ANNUITY_INCOME_RATIO'] = apps['AMT_ANNUITY']/apps['AMT_INCOME_TOTAL']\n",
        "    apps['APPS_CREDIT_INCOME_RATIO'] = apps['AMT_CREDIT']/apps['AMT_INCOME_TOTAL']\n",
        "    apps['APPS_GOODS_INCOME_RATIO'] = apps['AMT_GOODS_PRICE']/apps['AMT_INCOME_TOTAL']\n",
        "    apps['APPS_CNT_FAM_INCOME_RATIO'] = apps['AMT_INCOME_TOTAL']/apps['CNT_FAM_MEMBERS']\n",
        "    \n",
        "    # DAYS_BIRTH, DAYS_EMPLOYED 비율로 Feature 가공\n",
        "    apps['APPS_EMPLOYED_BIRTH_RATIO'] = apps['DAYS_EMPLOYED']/apps['DAYS_BIRTH']\n",
        "    apps['APPS_INCOME_EMPLOYED_RATIO'] = apps['AMT_INCOME_TOTAL']/apps['DAYS_EMPLOYED']\n",
        "    apps['APPS_INCOME_BIRTH_RATIO'] = apps['AMT_INCOME_TOTAL']/apps['DAYS_BIRTH']\n",
        "    apps['APPS_CAR_BIRTH_RATIO'] = apps['OWN_CAR_AGE'] / apps['DAYS_BIRTH']\n",
        "    apps['APPS_CAR_EMPLOYED_RATIO'] = apps['OWN_CAR_AGE'] / apps['DAYS_EMPLOYED']\n",
        "    \n",
        "    return apps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mU0PqE9vR4o"
      },
      "source": [
        "#### previous 데이터 가공후 인코딩 및 최종 데이터 집합 생성하는 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOSuDuMvvR4p"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "def get_prev_processed(prev):\n",
        "    # 대출 신청 금액과 실제 대출액/대출 상품금액 차이 및 비율\n",
        "    prev['PREV_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n",
        "    prev['PREV_GOODS_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_GOODS_PRICE']\n",
        "    prev['PREV_CREDIT_APPL_RATIO'] = prev['AMT_CREDIT']/prev['AMT_APPLICATION']\n",
        "    # prev['PREV_ANNUITY_APPL_RATIO'] = prev['AMT_ANNUITY']/prev['AMT_APPLICATION']\n",
        "    prev['PREV_GOODS_APPL_RATIO'] = prev['AMT_GOODS_PRICE']/prev['AMT_APPLICATION']\n",
        "    \n",
        "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
        "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
        "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
        "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
        "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
        "    # 첫번째 만기일과 마지막 만기일까지의 기간\n",
        "    prev['PREV_DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n",
        "    # 매월 납부 금액과 납부 횟수 곱해서 전체 납부 금액 구함. \n",
        "    all_pay = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n",
        "    # 전체 납부 금액 대비 AMT_CREDIT 비율을 구하고 여기에 다시 납부횟수로 나누어서 이자율 계산. \n",
        "    prev['PREV_INTERESTS_RATE'] = (all_pay/prev['AMT_CREDIT'] - 1)/prev['CNT_PAYMENT']\n",
        "        \n",
        "    return prev\n",
        "    \n",
        "    \n",
        "def get_prev_amt_agg(prev):\n",
        "    # 새롭게 생성된 대출 신청액 대비 다른 금액 차이 및 비율로 aggregation 수행. \n",
        "    agg_dict = {\n",
        "         # 기존 컬럼. \n",
        "        'SK_ID_CURR':['count'],\n",
        "        'AMT_CREDIT':['mean', 'max', 'sum'],\n",
        "        'AMT_ANNUITY':['mean', 'max', 'sum'], \n",
        "        'AMT_APPLICATION':['mean', 'max', 'sum'],\n",
        "        'AMT_DOWN_PAYMENT':['mean', 'max', 'sum'],\n",
        "        'AMT_GOODS_PRICE':['mean', 'max', 'sum'],\n",
        "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
        "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
        "        'CNT_PAYMENT': ['mean', 'sum'],\n",
        "        # 가공 컬럼\n",
        "        'PREV_CREDIT_DIFF':['mean', 'max', 'sum'], \n",
        "        'PREV_CREDIT_APPL_RATIO':['mean', 'max'],\n",
        "        'PREV_GOODS_DIFF':['mean', 'max', 'sum'],\n",
        "        'PREV_GOODS_APPL_RATIO':['mean', 'max'],\n",
        "        'PREV_DAYS_LAST_DUE_DIFF':['mean', 'max', 'sum'],\n",
        "        'PREV_INTERESTS_RATE':['mean', 'max']\n",
        "    }\n",
        "\n",
        "    prev_group = prev.groupby('SK_ID_CURR')\n",
        "    prev_amt_agg = prev_group.agg(agg_dict)\n",
        "\n",
        "    # multi index 컬럼을 '_'로 연결하여 컬럼명 변경\n",
        "    prev_amt_agg.columns = [\"PREV_\"+ \"_\".join(x).upper() for x in prev_amt_agg.columns.ravel()]\n",
        "    \n",
        "    return prev_amt_agg\n",
        "\n",
        "def get_prev_refused_appr_agg(prev):\n",
        "    # 원래 groupby 컬럼 + 세부 기준 컬럼으로 groupby 수행. 세분화된 레벨로 aggregation 수행 한 뒤에 unstack()으로 컬럼레벨로 변형. \n",
        "    prev_refused_appr_group = prev[prev['NAME_CONTRACT_STATUS'].isin(['Approved', 'Refused'])].groupby([ 'SK_ID_CURR', 'NAME_CONTRACT_STATUS'])\n",
        "    prev_refused_appr_agg = prev_refused_appr_group['SK_ID_CURR'].count().unstack()\n",
        "    # 컬럼명 변경. \n",
        "    prev_refused_appr_agg.columns = ['PREV_APPROVED_COUNT', 'PREV_REFUSED_COUNT' ]\n",
        "    # NaN값은 모두 0으로 변경. \n",
        "    prev_refused_appr_agg = prev_refused_appr_agg.fillna(0)\n",
        "    \n",
        "    return prev_refused_appr_agg\n",
        "\n",
        "    \n",
        "\n",
        "def get_prev_agg(prev):\n",
        "    prev = get_prev_processed(prev)\n",
        "    prev_amt_agg = get_prev_amt_agg(prev)\n",
        "    prev_refused_appr_agg = get_prev_refused_appr_agg(prev)\n",
        "    \n",
        "    # prev_amt_agg와 조인. \n",
        "    prev_agg = prev_amt_agg.merge(prev_refused_appr_agg, on='SK_ID_CURR', how='left')\n",
        "    # SK_ID_CURR별 과거 대출건수 대비 APPROVED_COUNT 및 REFUSED_COUNT 비율 생성. \n",
        "    prev_agg['PREV_REFUSED_RATIO'] = prev_agg['PREV_REFUSED_COUNT']/prev_agg['PREV_SK_ID_CURR_COUNT']\n",
        "    prev_agg['PREV_APPROVED_RATIO'] = prev_agg['PREV_APPROVED_COUNT']/prev_agg['PREV_SK_ID_CURR_COUNT']\n",
        "    # 'PREV_REFUSED_COUNT', 'PREV_APPROVED_COUNT' 컬럼 drop \n",
        "    prev_agg = prev_agg.drop(['PREV_REFUSED_COUNT', 'PREV_APPROVED_COUNT'], axis=1)\n",
        "    \n",
        "    return prev_agg\n",
        "\n",
        "def get_apps_all_with_prev_agg(apps, prev):\n",
        "    apps_all =  get_apps_processed(apps)\n",
        "    prev_agg = get_prev_agg(prev)\n",
        "    print('prev_agg shape:', prev_agg.shape)\n",
        "    print('apps_all before merge shape:', apps_all.shape)\n",
        "    apps_all = apps_all.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
        "    print('apps_all after merge with prev_agg shape:', apps_all.shape)\n",
        "    \n",
        "    return apps_all\n",
        "\n",
        "def get_apps_all_encoded(apps_all):\n",
        "    object_columns = apps_all.dtypes[apps_all.dtypes == 'object'].index.tolist()\n",
        "    for column in object_columns:\n",
        "        apps_all[column] = pd.factorize(apps_all[column])[0]\n",
        "    \n",
        "    return apps_all\n",
        "\n",
        "def get_apps_all_train_test(apps_all):\n",
        "    apps_all_train = apps_all[~apps_all['TARGET'].isnull()]\n",
        "    apps_all_test = apps_all[apps_all['TARGET'].isnull()]\n",
        "\n",
        "    apps_all_test = apps_all_test.drop('TARGET', axis=1)\n",
        "    \n",
        "    return apps_all_train, apps_all_test\n",
        "    \n",
        "def train_apps_all(apps_all_train):\n",
        "    ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
        "    target_app = apps_all_train['TARGET']\n",
        "\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(ftr_app, target_app, test_size=0.3, random_state=2020)\n",
        "    print('train shape:', train_x.shape, 'valid shape:', valid_x.shape)\n",
        "    clf = LGBMClassifier(\n",
        "                nthread=4,\n",
        "                n_estimators=2000,\n",
        "                learning_rate=0.01,\n",
        "                num_leaves=32,\n",
        "                colsample_bytree=0.8,\n",
        "                subsample=0.8,\n",
        "                max_depth=8,\n",
        "                reg_alpha=0.04,\n",
        "                reg_lambda=0.07,\n",
        "                min_child_weight=40,\n",
        "                silent=-1,\n",
        "                verbose=-1,\n",
        "                )\n",
        "\n",
        "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 100, \n",
        "                early_stopping_rounds= 100)\n",
        "    \n",
        "    return clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqqmKKhrvR4w"
      },
      "source": [
        "##### 최종 집합 생성 및 인코딩, 학습/테스트 데이터 분리, 학습/검증 피처와 타겟 데이터 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vsBLQ8FvR4x",
        "outputId": "518e2588-a6ee-4a21-8ec0-e34f22975b4c"
      },
      "source": [
        "apps_all = get_apps_all_with_prev_agg(apps, prev)\n",
        "apps_all = get_apps_all_encoded(apps_all)\n",
        "apps_all_train, apps_all_test = get_apps_all_train_test(apps_all)\n",
        "ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
        "target_app = apps_all_train['TARGET']\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(ftr_app, target_app, test_size=0.3, random_state=2020)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prev_agg shape: (338857, 41)\n",
            "apps_all before merge shape: (356255, 135)\n",
            "apps_all after merge with prev_agg shape: (356255, 176)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEOB24lVvR47"
      },
      "source": [
        "#### Bayesian Optimization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDf92dTOw0rR",
        "outputId": "9d802ac9-79ab-4eac-b536-7c9bc1729ac5"
      },
      "source": [
        "# bayesian optimization 패키지 설치\n",
        "!pip install bayesian-optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7a/fd8059a3881d3ab37ac8f72f56b73937a14e8bb14a9733e68cc8b17dbe3c/bayesian-optimization-1.2.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.19.4)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.0)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-cp36-none-any.whl size=11685 sha256=ea8c5a802979d13e76abd53419a5528fdbb681a1c006555bb611049c0ba025d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/56/ae/e0e3c1fc1954dc3ec712e2df547235ed072b448094d8f94aec\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDQVRZeRvR48"
      },
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from lightgbm import LGBMClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDmrYrAUvR5B"
      },
      "source": [
        "##### 함수의 입력값 search 범위(하이퍼 파라미터 별 입력 범위) 를 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrIZzOHbvR5C"
      },
      "source": [
        "# 이러한 파라미터값들은 하다보면 어느정도로 줘야하는지 감이 생긴다\r\n",
        "# subsample값은 0 에서 1 사이로 주는데 0.5 이하는 의미가없다\r\n",
        "bayesian_params = {\r\n",
        "    'max_depth': (6, 16), \r\n",
        "    'num_leaves': (24, 64), \r\n",
        "    'min_child_samples': (10, 200), \r\n",
        "    'min_child_weight':(1, 50),\r\n",
        "    'subsample':(0.5, 1.0),\r\n",
        "    'colsample_bytree': (0.5, 1.0),\r\n",
        "    'max_bin':(10, 500),\r\n",
        "    'reg_lambda':(0.001, 10),\r\n",
        "    'reg_alpha': (0.01, 50) \r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yog23y34vR5H"
      },
      "source": [
        "##### 최대 값을 구할 함수 선언. \n",
        "* iteration 시 마다 hyperparameter를 입력받아 classifier 학습하고 roc_auc_score값을 반환 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YduL1j4RvR5J"
      },
      "source": [
        "# roc_auc를 최대화 해주는 함수값을 찾는다\r\n",
        "# BayesianOptimization의 maximize를 할때마다 lgb_roc_eval을 호출한다\r\n",
        "# bayesian_params의 파라미터 범위중 하나의 값이 들어옴, ex) max_depth라면 6.1일수도있고 7일수도있다. \r\n",
        "# params의 인자는 정수가 들어가야해서 처리를 해줘야한다.\r\n",
        "\r\n",
        "def lgb_roc_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \r\n",
        "                colsample_bytree,max_bin, reg_lambda, reg_alpha):\r\n",
        "  # subsample은 0과1 사이의 값이 들어가야해서 다시한번 체크해준다.\r\n",
        "    params = {\r\n",
        "        \"n_estimators\":500, \"learning_rate\":0.02,\r\n",
        "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경, round는 반올림\r\n",
        "        'num_leaves': int(round(num_leaves)), \r\n",
        "        'min_child_samples': int(round(min_child_samples)),\r\n",
        "        'min_child_weight': int(round(min_child_weight)),\r\n",
        "        'subsample': max(min(subsample, 1), 0), \r\n",
        "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\r\n",
        "        'max_bin':  max(int(round(max_bin)),10),\r\n",
        "        'reg_lambda': max(reg_lambda,0),\r\n",
        "        'reg_alpha': max(reg_alpha, 0)\r\n",
        "    }\r\n",
        "    print(params)\r\n",
        "    lgb_model = LGBMClassifier(**params)\r\n",
        "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 100, \r\n",
        "                early_stopping_rounds= 100)\r\n",
        "    valid_proba = lgb_model.predict_proba(valid_x)[:, 1]\r\n",
        "    roc_auc = roc_auc_score(valid_y, valid_proba)\r\n",
        "    \r\n",
        "    return roc_auc   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmnQwMudvR5Q"
      },
      "source": [
        "##### BayesianOptimization 객체 생성 후 함수 반환값이 최대가 되는 입력값 search를 위한 iteration 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcny5qJrvR5R",
        "scrolled": true,
        "outputId": "ea5d8d61-ba18-46d0-a491-c7d5ea3590fb"
      },
      "source": [
        "# BayesianOptimization객체를 수행할 함수와 search할 parameter 범위를 설정하여 생성. \r\n",
        "lgbBO = BayesianOptimization(lgb_roc_eval,bayesian_params , random_state=0)\r\n",
        "# 함수 반환값이 최대가 되는 입력값 유추를 위한 iteration 수행. \r\n",
        "lgbBO.maximize(init_points=5, n_iter=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | colsam... |  max_bin  | max_depth | min_ch... | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.246055\ttraining's auc: 0.769441\tvalid_1's binary_logloss: 0.248931\tvalid_1's auc: 0.755295\n",
            "[200]\ttraining's binary_logloss: 0.238455\ttraining's auc: 0.787337\tvalid_1's binary_logloss: 0.244205\tvalid_1's auc: 0.766208\n",
            "[300]\ttraining's binary_logloss: 0.234009\ttraining's auc: 0.798843\tvalid_1's binary_logloss: 0.242347\tvalid_1's auc: 0.771365\n",
            "[400]\ttraining's binary_logloss: 0.230658\ttraining's auc: 0.807905\tvalid_1's binary_logloss: 0.241451\tvalid_1's auc: 0.773881\n",
            "[500]\ttraining's binary_logloss: 0.227681\ttraining's auc: 0.816051\tvalid_1's binary_logloss: 0.240888\tvalid_1's auc: 0.775474\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.227681\ttraining's auc: 0.816051\tvalid_1's binary_logloss: 0.240888\tvalid_1's auc: 0.775474\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7755  \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 360.4   \u001b[0m | \u001b[0m 12.03   \u001b[0m | \u001b[0m 113.5   \u001b[0m | \u001b[0m 21.76   \u001b[0m | \u001b[0m 49.84   \u001b[0m | \u001b[0m 21.88   \u001b[0m | \u001b[0m 8.918   \u001b[0m | \u001b[0m 0.9818  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.247403\ttraining's auc: 0.762607\tvalid_1's binary_logloss: 0.249078\tvalid_1's auc: 0.753906\n",
            "[200]\ttraining's binary_logloss: 0.240422\ttraining's auc: 0.780221\tvalid_1's binary_logloss: 0.244242\tvalid_1's auc: 0.765727\n",
            "[300]\ttraining's binary_logloss: 0.236479\ttraining's auc: 0.790896\tvalid_1's binary_logloss: 0.242327\tvalid_1's auc: 0.77103\n",
            "[400]\ttraining's binary_logloss: 0.233521\ttraining's auc: 0.799101\tvalid_1's binary_logloss: 0.2413\tvalid_1's auc: 0.773901\n",
            "[500]\ttraining's binary_logloss: 0.231078\ttraining's auc: 0.805962\tvalid_1's binary_logloss: 0.240762\tvalid_1's auc: 0.775357\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.231078\ttraining's auc: 0.805962\tvalid_1's binary_logloss: 0.240762\tvalid_1's auc: 0.775357\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7754  \u001b[0m | \u001b[0m 0.6917  \u001b[0m | \u001b[0m 397.9   \u001b[0m | \u001b[0m 11.29   \u001b[0m | \u001b[0m 117.9   \u001b[0m | \u001b[0m 46.35   \u001b[0m | \u001b[0m 26.84   \u001b[0m | \u001b[0m 4.366   \u001b[0m | \u001b[0m 0.2032  \u001b[0m | \u001b[0m 0.9163  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243787\ttraining's auc: 0.775984\tvalid_1's binary_logloss: 0.247887\tvalid_1's auc: 0.757669\n",
            "[200]\ttraining's binary_logloss: 0.234957\ttraining's auc: 0.797205\tvalid_1's binary_logloss: 0.243121\tvalid_1's auc: 0.769013\n",
            "[300]\ttraining's binary_logloss: 0.22917\ttraining's auc: 0.812302\tvalid_1's binary_logloss: 0.241429\tvalid_1's auc: 0.773828\n",
            "[400]\ttraining's binary_logloss: 0.224408\ttraining's auc: 0.824959\tvalid_1's binary_logloss: 0.240536\tvalid_1's auc: 0.776324\n",
            "[500]\ttraining's binary_logloss: 0.220334\ttraining's auc: 0.835945\tvalid_1's binary_logloss: 0.240167\tvalid_1's auc: 0.777332\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.220334\ttraining's auc: 0.835945\tvalid_1's binary_logloss: 0.240167\tvalid_1's auc: 0.777332\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7773  \u001b[0m | \u001b[95m 0.8891  \u001b[0m | \u001b[95m 436.3   \u001b[0m | \u001b[95m 15.79   \u001b[0m | \u001b[95m 161.8   \u001b[0m | \u001b[95m 23.61   \u001b[0m | \u001b[95m 55.22   \u001b[0m | \u001b[95m 5.923   \u001b[0m | \u001b[95m 6.4     \u001b[0m | \u001b[95m 0.5717  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.246899\ttraining's auc: 0.765744\tvalid_1's binary_logloss: 0.249215\tvalid_1's auc: 0.753886\n",
            "[200]\ttraining's binary_logloss: 0.239831\ttraining's auc: 0.782824\tvalid_1's binary_logloss: 0.24453\tvalid_1's auc: 0.765228\n",
            "[300]\ttraining's binary_logloss: 0.235787\ttraining's auc: 0.79353\tvalid_1's binary_logloss: 0.2426\tvalid_1's auc: 0.770618\n",
            "[400]\ttraining's binary_logloss: 0.232814\ttraining's auc: 0.801566\tvalid_1's binary_logloss: 0.241576\tvalid_1's auc: 0.773499\n",
            "[500]\ttraining's binary_logloss: 0.230355\ttraining's auc: 0.808263\tvalid_1's binary_logloss: 0.241041\tvalid_1's auc: 0.774994\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.230355\ttraining's auc: 0.808263\tvalid_1's binary_logloss: 0.241041\tvalid_1's auc: 0.774994\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.775   \u001b[0m | \u001b[0m 0.9723  \u001b[0m | \u001b[0m 265.7   \u001b[0m | \u001b[0m 10.15   \u001b[0m | \u001b[0m 60.27   \u001b[0m | \u001b[0m 38.94   \u001b[0m | \u001b[0m 42.25   \u001b[0m | \u001b[0m 28.43   \u001b[0m | \u001b[0m 0.1889  \u001b[0m | \u001b[0m 0.8088  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.247324\ttraining's auc: 0.765749\tvalid_1's binary_logloss: 0.249617\tvalid_1's auc: 0.753702\n",
            "[200]\ttraining's binary_logloss: 0.240353\ttraining's auc: 0.781611\tvalid_1's binary_logloss: 0.244878\tvalid_1's auc: 0.764481\n",
            "[300]\ttraining's binary_logloss: 0.236528\ttraining's auc: 0.791576\tvalid_1's binary_logloss: 0.242979\tvalid_1's auc: 0.769669\n",
            "[400]\ttraining's binary_logloss: 0.233771\ttraining's auc: 0.799079\tvalid_1's binary_logloss: 0.242037\tvalid_1's auc: 0.772325\n",
            "[500]\ttraining's binary_logloss: 0.231415\ttraining's auc: 0.805611\tvalid_1's binary_logloss: 0.241404\tvalid_1's auc: 0.774198\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.231415\ttraining's auc: 0.805611\tvalid_1's binary_logloss: 0.241404\tvalid_1's auc: 0.774198\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7742  \u001b[0m | \u001b[0m 0.806   \u001b[0m | \u001b[0m 312.3   \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 139.5   \u001b[0m | \u001b[0m 18.62   \u001b[0m | \u001b[0m 41.48   \u001b[0m | \u001b[0m 34.88   \u001b[0m | \u001b[0m 0.6032  \u001b[0m | \u001b[0m 0.8334  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.24729\ttraining's auc: 0.765974\tvalid_1's binary_logloss: 0.249608\tvalid_1's auc: 0.753298\n",
            "[200]\ttraining's binary_logloss: 0.240351\ttraining's auc: 0.782182\tvalid_1's binary_logloss: 0.244735\tvalid_1's auc: 0.764937\n",
            "[300]\ttraining's binary_logloss: 0.236658\ttraining's auc: 0.791597\tvalid_1's binary_logloss: 0.242811\tvalid_1's auc: 0.770094\n",
            "[400]\ttraining's binary_logloss: 0.234003\ttraining's auc: 0.798618\tvalid_1's binary_logloss: 0.241848\tvalid_1's auc: 0.772785\n",
            "[500]\ttraining's binary_logloss: 0.231862\ttraining's auc: 0.80432\tvalid_1's binary_logloss: 0.241265\tvalid_1's auc: 0.774314\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.231862\ttraining's auc: 0.80432\tvalid_1's binary_logloss: 0.241265\tvalid_1's auc: 0.774314\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7743  \u001b[0m | \u001b[0m 0.8538  \u001b[0m | \u001b[0m 499.2   \u001b[0m | \u001b[0m 7.119   \u001b[0m | \u001b[0m 10.4    \u001b[0m | \u001b[0m 37.64   \u001b[0m | \u001b[0m 46.75   \u001b[0m | \u001b[0m 34.55   \u001b[0m | \u001b[0m 7.535   \u001b[0m | \u001b[0m 0.7468  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.246977\ttraining's auc: 0.765969\tvalid_1's binary_logloss: 0.249416\tvalid_1's auc: 0.753264\n",
            "[200]\ttraining's binary_logloss: 0.239697\ttraining's auc: 0.78383\tvalid_1's binary_logloss: 0.244979\tvalid_1's auc: 0.76387\n",
            "[300]\ttraining's binary_logloss: 0.235487\ttraining's auc: 0.795076\tvalid_1's binary_logloss: 0.243362\tvalid_1's auc: 0.768285\n",
            "[400]\ttraining's binary_logloss: 0.232212\ttraining's auc: 0.804034\tvalid_1's binary_logloss: 0.242589\tvalid_1's auc: 0.770586\n",
            "[500]\ttraining's binary_logloss: 0.22931\ttraining's auc: 0.812016\tvalid_1's binary_logloss: 0.242104\tvalid_1's auc: 0.772006\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.22931\ttraining's auc: 0.812016\tvalid_1's binary_logloss: 0.242104\tvalid_1's auc: 0.772006\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.772   \u001b[0m | \u001b[0m 0.9751  \u001b[0m | \u001b[0m 12.5    \u001b[0m | \u001b[0m 15.87   \u001b[0m | \u001b[0m 199.1   \u001b[0m | \u001b[0m 43.33   \u001b[0m | \u001b[0m 53.78   \u001b[0m | \u001b[0m 14.98   \u001b[0m | \u001b[0m 9.61    \u001b[0m | \u001b[0m 0.7368  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.245827\ttraining's auc: 0.772591\tvalid_1's binary_logloss: 0.248613\tvalid_1's auc: 0.757999\n",
            "[200]\ttraining's binary_logloss: 0.23821\ttraining's auc: 0.788947\tvalid_1's binary_logloss: 0.243834\tvalid_1's auc: 0.767444\n",
            "[300]\ttraining's binary_logloss: 0.233809\ttraining's auc: 0.800036\tvalid_1's binary_logloss: 0.242037\tvalid_1's auc: 0.772049\n",
            "[400]\ttraining's binary_logloss: 0.230765\ttraining's auc: 0.807812\tvalid_1's binary_logloss: 0.241178\tvalid_1's auc: 0.774289\n",
            "[500]\ttraining's binary_logloss: 0.228071\ttraining's auc: 0.815026\tvalid_1's binary_logloss: 0.240678\tvalid_1's auc: 0.775654\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.228071\ttraining's auc: 0.815026\tvalid_1's binary_logloss: 0.240678\tvalid_1's auc: 0.775654\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7757  \u001b[0m | \u001b[0m 0.5607  \u001b[0m | \u001b[0m 497.7   \u001b[0m | \u001b[0m 7.087   \u001b[0m | \u001b[0m 199.5   \u001b[0m | \u001b[0m 48.53   \u001b[0m | \u001b[0m 46.57   \u001b[0m | \u001b[0m 8.796   \u001b[0m | \u001b[0m 5.276   \u001b[0m | \u001b[0m 0.8411  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.248462\ttraining's auc: 0.760337\tvalid_1's binary_logloss: 0.25014\tvalid_1's auc: 0.751039\n",
            "[200]\ttraining's binary_logloss: 0.241973\ttraining's auc: 0.776251\tvalid_1's binary_logloss: 0.245444\tvalid_1's auc: 0.762675\n",
            "[300]\ttraining's binary_logloss: 0.238475\ttraining's auc: 0.785699\tvalid_1's binary_logloss: 0.24349\tvalid_1's auc: 0.768207\n",
            "[400]\ttraining's binary_logloss: 0.236043\ttraining's auc: 0.792287\tvalid_1's binary_logloss: 0.242475\tvalid_1's auc: 0.771064\n",
            "[500]\ttraining's binary_logloss: 0.234105\ttraining's auc: 0.797673\tvalid_1's binary_logloss: 0.241873\tvalid_1's auc: 0.772756\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.234105\ttraining's auc: 0.797673\tvalid_1's binary_logloss: 0.241873\tvalid_1's auc: 0.772756\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7728  \u001b[0m | \u001b[0m 0.9722  \u001b[0m | \u001b[0m 497.8   \u001b[0m | \u001b[0m 15.76   \u001b[0m | \u001b[0m 197.6   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 32.35   \u001b[0m | \u001b[0m 43.15   \u001b[0m | \u001b[0m 0.1655  \u001b[0m | \u001b[0m 0.6483  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.246026\ttraining's auc: 0.770519\tvalid_1's binary_logloss: 0.24849\tvalid_1's auc: 0.758188\n",
            "[200]\ttraining's binary_logloss: 0.238356\ttraining's auc: 0.787168\tvalid_1's binary_logloss: 0.243546\tvalid_1's auc: 0.768022\n",
            "[300]\ttraining's binary_logloss: 0.233805\ttraining's auc: 0.799067\tvalid_1's binary_logloss: 0.241798\tvalid_1's auc: 0.772513\n",
            "[400]\ttraining's binary_logloss: 0.230316\ttraining's auc: 0.808398\tvalid_1's binary_logloss: 0.24088\tvalid_1's auc: 0.775054\n",
            "[500]\ttraining's binary_logloss: 0.227288\ttraining's auc: 0.816777\tvalid_1's binary_logloss: 0.24038\tvalid_1's auc: 0.776491\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.227288\ttraining's auc: 0.816777\tvalid_1's binary_logloss: 0.24038\tvalid_1's auc: 0.776491\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7765  \u001b[0m | \u001b[0m 0.5342  \u001b[0m | \u001b[0m 489.9   \u001b[0m | \u001b[0m 8.998   \u001b[0m | \u001b[0m 10.21   \u001b[0m | \u001b[0m 39.73   \u001b[0m | \u001b[0m 36.51   \u001b[0m | \u001b[0m 1.809   \u001b[0m | \u001b[0m 5.04    \u001b[0m | \u001b[0m 0.5383  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.242511\ttraining's auc: 0.780728\tvalid_1's binary_logloss: 0.247498\tvalid_1's auc: 0.759611\n",
            "[200]\ttraining's binary_logloss: 0.232956\ttraining's auc: 0.803019\tvalid_1's binary_logloss: 0.242928\tvalid_1's auc: 0.769376\n",
            "[300]\ttraining's binary_logloss: 0.226632\ttraining's auc: 0.819394\tvalid_1's binary_logloss: 0.241396\tvalid_1's auc: 0.773595\n",
            "[400]\ttraining's binary_logloss: 0.221355\ttraining's auc: 0.833168\tvalid_1's binary_logloss: 0.240554\tvalid_1's auc: 0.775995\n",
            "[500]\ttraining's binary_logloss: 0.216921\ttraining's auc: 0.844707\tvalid_1's binary_logloss: 0.240233\tvalid_1's auc: 0.776863\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.216921\ttraining's auc: 0.844707\tvalid_1's binary_logloss: 0.240233\tvalid_1's auc: 0.776863\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7769  \u001b[0m | \u001b[0m 0.6872  \u001b[0m | \u001b[0m 479.6   \u001b[0m | \u001b[0m 10.23   \u001b[0m | \u001b[0m 24.87   \u001b[0m | \u001b[0m 6.99    \u001b[0m | \u001b[0m 60.1    \u001b[0m | \u001b[0m 0.8071  \u001b[0m | \u001b[0m 5.777   \u001b[0m | \u001b[0m 0.7787  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.24234\ttraining's auc: 0.781101\tvalid_1's binary_logloss: 0.24728\tvalid_1's auc: 0.760147\n",
            "[200]\ttraining's binary_logloss: 0.2327\ttraining's auc: 0.803437\tvalid_1's binary_logloss: 0.24258\tvalid_1's auc: 0.770345\n",
            "[300]\ttraining's binary_logloss: 0.22623\ttraining's auc: 0.82016\tvalid_1's binary_logloss: 0.241016\tvalid_1's auc: 0.77462\n",
            "[400]\ttraining's binary_logloss: 0.220907\ttraining's auc: 0.834068\tvalid_1's binary_logloss: 0.24032\tvalid_1's auc: 0.776459\n",
            "[500]\ttraining's binary_logloss: 0.21622\ttraining's auc: 0.846267\tvalid_1's binary_logloss: 0.239929\tvalid_1's auc: 0.777578\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.21622\ttraining's auc: 0.846267\tvalid_1's binary_logloss: 0.239929\tvalid_1's auc: 0.777578\n",
            "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.7776  \u001b[0m | \u001b[95m 0.6874  \u001b[0m | \u001b[95m 479.6   \u001b[0m | \u001b[95m 15.62   \u001b[0m | \u001b[95m 15.73   \u001b[0m | \u001b[95m 46.02   \u001b[0m | \u001b[95m 60.62   \u001b[0m | \u001b[95m 0.6881  \u001b[0m | \u001b[95m 2.142   \u001b[0m | \u001b[95m 0.9413  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.242621\ttraining's auc: 0.777962\tvalid_1's binary_logloss: 0.247394\tvalid_1's auc: 0.758094\n",
            "[200]\ttraining's binary_logloss: 0.23316\ttraining's auc: 0.801477\tvalid_1's binary_logloss: 0.242854\tvalid_1's auc: 0.769493\n",
            "[300]\ttraining's binary_logloss: 0.226772\ttraining's auc: 0.818268\tvalid_1's binary_logloss: 0.241209\tvalid_1's auc: 0.77417\n",
            "[400]\ttraining's binary_logloss: 0.221626\ttraining's auc: 0.831748\tvalid_1's binary_logloss: 0.240519\tvalid_1's auc: 0.776221\n",
            "[500]\ttraining's binary_logloss: 0.217126\ttraining's auc: 0.843541\tvalid_1's binary_logloss: 0.240284\tvalid_1's auc: 0.776981\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.217126\ttraining's auc: 0.843541\tvalid_1's binary_logloss: 0.240284\tvalid_1's auc: 0.776981\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.777   \u001b[0m | \u001b[0m 0.9558  \u001b[0m | \u001b[0m 493.2   \u001b[0m | \u001b[0m 15.27   \u001b[0m | \u001b[0m 18.25   \u001b[0m | \u001b[0m 40.87   \u001b[0m | \u001b[0m 55.51   \u001b[0m | \u001b[0m 0.4371  \u001b[0m | \u001b[0m 1.348   \u001b[0m | \u001b[0m 0.9353  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.245377\ttraining's auc: 0.770294\tvalid_1's binary_logloss: 0.248285\tvalid_1's auc: 0.756901\n",
            "[200]\ttraining's binary_logloss: 0.237373\ttraining's auc: 0.790013\tvalid_1's binary_logloss: 0.243599\tvalid_1's auc: 0.767528\n",
            "[300]\ttraining's binary_logloss: 0.232274\ttraining's auc: 0.803834\tvalid_1's binary_logloss: 0.241778\tvalid_1's auc: 0.772592\n",
            "[400]\ttraining's binary_logloss: 0.228236\ttraining's auc: 0.814922\tvalid_1's binary_logloss: 0.240883\tvalid_1's auc: 0.775084\n",
            "[500]\ttraining's binary_logloss: 0.224852\ttraining's auc: 0.824481\tvalid_1's binary_logloss: 0.240454\tvalid_1's auc: 0.776298\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.224852\ttraining's auc: 0.824481\tvalid_1's binary_logloss: 0.240454\tvalid_1's auc: 0.776298\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7763  \u001b[0m | \u001b[0m 0.6557  \u001b[0m | \u001b[0m 489.9   \u001b[0m | \u001b[0m 10.31   \u001b[0m | \u001b[0m 17.82   \u001b[0m | \u001b[0m 1.049   \u001b[0m | \u001b[0m 37.8    \u001b[0m | \u001b[0m 1.685   \u001b[0m | \u001b[0m 1.641   \u001b[0m | \u001b[0m 0.5974  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243502\ttraining's auc: 0.779578\tvalid_1's binary_logloss: 0.247815\tvalid_1's auc: 0.759968\n",
            "[200]\ttraining's binary_logloss: 0.234257\ttraining's auc: 0.799832\tvalid_1's binary_logloss: 0.242909\tvalid_1's auc: 0.769824\n",
            "[300]\ttraining's binary_logloss: 0.228301\ttraining's auc: 0.815048\tvalid_1's binary_logloss: 0.241274\tvalid_1's auc: 0.773989\n",
            "[400]\ttraining's binary_logloss: 0.223315\ttraining's auc: 0.82824\tvalid_1's binary_logloss: 0.240403\tvalid_1's auc: 0.776412\n",
            "[500]\ttraining's binary_logloss: 0.218993\ttraining's auc: 0.839625\tvalid_1's binary_logloss: 0.240016\tvalid_1's auc: 0.777459\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.218993\ttraining's auc: 0.839625\tvalid_1's binary_logloss: 0.240016\tvalid_1's auc: 0.777459\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7775  \u001b[0m | \u001b[0m 0.5838  \u001b[0m | \u001b[0m 478.1   \u001b[0m | \u001b[0m 15.33   \u001b[0m | \u001b[0m 16.94   \u001b[0m | \u001b[0m 43.66   \u001b[0m | \u001b[0m 58.1    \u001b[0m | \u001b[0m 1.873   \u001b[0m | \u001b[0m 6.926   \u001b[0m | \u001b[0m 0.821   \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.24262\ttraining's auc: 0.780136\tvalid_1's binary_logloss: 0.247505\tvalid_1's auc: 0.758714\n",
            "[200]\ttraining's binary_logloss: 0.233017\ttraining's auc: 0.802917\tvalid_1's binary_logloss: 0.242809\tvalid_1's auc: 0.769682\n",
            "[300]\ttraining's binary_logloss: 0.22659\ttraining's auc: 0.819451\tvalid_1's binary_logloss: 0.241334\tvalid_1's auc: 0.773752\n",
            "[400]\ttraining's binary_logloss: 0.221277\ttraining's auc: 0.833328\tvalid_1's binary_logloss: 0.240514\tvalid_1's auc: 0.776042\n",
            "[500]\ttraining's binary_logloss: 0.216682\ttraining's auc: 0.845115\tvalid_1's binary_logloss: 0.240115\tvalid_1's auc: 0.777182\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.216682\ttraining's auc: 0.845115\tvalid_1's binary_logloss: 0.240115\tvalid_1's auc: 0.777182\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7772  \u001b[0m | \u001b[0m 0.879   \u001b[0m | \u001b[0m 487.3   \u001b[0m | \u001b[0m 13.74   \u001b[0m | \u001b[0m 22.79   \u001b[0m | \u001b[0m 47.05   \u001b[0m | \u001b[0m 63.32   \u001b[0m | \u001b[0m 1.131   \u001b[0m | \u001b[0m 9.356   \u001b[0m | \u001b[0m 0.8718  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243214\ttraining's auc: 0.778553\tvalid_1's binary_logloss: 0.247681\tvalid_1's auc: 0.759151\n",
            "[200]\ttraining's binary_logloss: 0.233945\ttraining's auc: 0.800338\tvalid_1's binary_logloss: 0.242867\tvalid_1's auc: 0.769981\n",
            "[300]\ttraining's binary_logloss: 0.227839\ttraining's auc: 0.816293\tvalid_1's binary_logloss: 0.241216\tvalid_1's auc: 0.774466\n",
            "[400]\ttraining's binary_logloss: 0.222764\ttraining's auc: 0.829769\tvalid_1's binary_logloss: 0.240344\tvalid_1's auc: 0.77684\n",
            "[500]\ttraining's binary_logloss: 0.218495\ttraining's auc: 0.84098\tvalid_1's binary_logloss: 0.239917\tvalid_1's auc: 0.778048\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.218495\ttraining's auc: 0.84098\tvalid_1's binary_logloss: 0.239917\tvalid_1's auc: 0.778048\n",
            "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.778   \u001b[0m | \u001b[95m 0.7437  \u001b[0m | \u001b[95m 494.7   \u001b[0m | \u001b[95m 14.27   \u001b[0m | \u001b[95m 25.78   \u001b[0m | \u001b[95m 2.691   \u001b[0m | \u001b[95m 57.97   \u001b[0m | \u001b[95m 2.47    \u001b[0m | \u001b[95m 9.797   \u001b[0m | \u001b[95m 0.5824  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243089\ttraining's auc: 0.779663\tvalid_1's binary_logloss: 0.247772\tvalid_1's auc: 0.759328\n",
            "[200]\ttraining's binary_logloss: 0.233916\ttraining's auc: 0.800579\tvalid_1's binary_logloss: 0.242989\tvalid_1's auc: 0.769592\n",
            "[300]\ttraining's binary_logloss: 0.227961\ttraining's auc: 0.81581\tvalid_1's binary_logloss: 0.24136\tvalid_1's auc: 0.773922\n",
            "[400]\ttraining's binary_logloss: 0.223086\ttraining's auc: 0.828448\tvalid_1's binary_logloss: 0.240452\tvalid_1's auc: 0.776537\n",
            "[500]\ttraining's binary_logloss: 0.218765\ttraining's auc: 0.839689\tvalid_1's binary_logloss: 0.239969\tvalid_1's auc: 0.777791\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.218765\ttraining's auc: 0.839689\tvalid_1's binary_logloss: 0.239969\tvalid_1's auc: 0.777791\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7778  \u001b[0m | \u001b[0m 0.6975  \u001b[0m | \u001b[0m 467.5   \u001b[0m | \u001b[0m 10.23   \u001b[0m | \u001b[0m 22.57   \u001b[0m | \u001b[0m 3.607   \u001b[0m | \u001b[0m 62.53   \u001b[0m | \u001b[0m 5.255   \u001b[0m | \u001b[0m 8.662   \u001b[0m | \u001b[0m 0.7036  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243329\ttraining's auc: 0.780078\tvalid_1's binary_logloss: 0.247818\tvalid_1's auc: 0.760092\n",
            "[200]\ttraining's binary_logloss: 0.234107\ttraining's auc: 0.800394\tvalid_1's binary_logloss: 0.242928\tvalid_1's auc: 0.770018\n",
            "[300]\ttraining's binary_logloss: 0.228138\ttraining's auc: 0.815651\tvalid_1's binary_logloss: 0.241298\tvalid_1's auc: 0.774223\n",
            "[400]\ttraining's binary_logloss: 0.223197\ttraining's auc: 0.828422\tvalid_1's binary_logloss: 0.240427\tvalid_1's auc: 0.776583\n",
            "[500]\ttraining's binary_logloss: 0.218904\ttraining's auc: 0.83973\tvalid_1's binary_logloss: 0.23993\tvalid_1's auc: 0.777942\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.218904\ttraining's auc: 0.83973\tvalid_1's binary_logloss: 0.23993\tvalid_1's auc: 0.777942\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7779  \u001b[0m | \u001b[0m 0.5437  \u001b[0m | \u001b[0m 488.4   \u001b[0m | \u001b[0m 10.29   \u001b[0m | \u001b[0m 45.29   \u001b[0m | \u001b[0m 1.819   \u001b[0m | \u001b[0m 62.43   \u001b[0m | \u001b[0m 3.419   \u001b[0m | \u001b[0m 9.019   \u001b[0m | \u001b[0m 0.6595  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.244805\ttraining's auc: 0.775537\tvalid_1's binary_logloss: 0.248491\tvalid_1's auc: 0.756923\n",
            "[200]\ttraining's binary_logloss: 0.236787\ttraining's auc: 0.794163\tvalid_1's binary_logloss: 0.243937\tvalid_1's auc: 0.766883\n",
            "[300]\ttraining's binary_logloss: 0.232062\ttraining's auc: 0.806155\tvalid_1's binary_logloss: 0.242106\tvalid_1's auc: 0.771886\n",
            "[400]\ttraining's binary_logloss: 0.228602\ttraining's auc: 0.814888\tvalid_1's binary_logloss: 0.241263\tvalid_1's auc: 0.774125\n",
            "[500]\ttraining's binary_logloss: 0.225643\ttraining's auc: 0.822414\tvalid_1's binary_logloss: 0.240776\tvalid_1's auc: 0.775568\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.225643\ttraining's auc: 0.822414\tvalid_1's binary_logloss: 0.240776\tvalid_1's auc: 0.775568\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7756  \u001b[0m | \u001b[0m 0.7745  \u001b[0m | \u001b[0m 488.7   \u001b[0m | \u001b[0m 6.037   \u001b[0m | \u001b[0m 34.42   \u001b[0m | \u001b[0m 5.833   \u001b[0m | \u001b[0m 60.81   \u001b[0m | \u001b[0m 7.308   \u001b[0m | \u001b[0m 0.9877  \u001b[0m | \u001b[0m 0.5466  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243236\ttraining's auc: 0.779669\tvalid_1's binary_logloss: 0.247666\tvalid_1's auc: 0.759311\n",
            "[200]\ttraining's binary_logloss: 0.234339\ttraining's auc: 0.799996\tvalid_1's binary_logloss: 0.243003\tvalid_1's auc: 0.769514\n",
            "[300]\ttraining's binary_logloss: 0.229103\ttraining's auc: 0.813046\tvalid_1's binary_logloss: 0.241444\tvalid_1's auc: 0.773553\n",
            "[400]\ttraining's binary_logloss: 0.22518\ttraining's auc: 0.823131\tvalid_1's binary_logloss: 0.240737\tvalid_1's auc: 0.775455\n",
            "[500]\ttraining's binary_logloss: 0.221873\ttraining's auc: 0.831569\tvalid_1's binary_logloss: 0.240306\tvalid_1's auc: 0.77665\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.221873\ttraining's auc: 0.831569\tvalid_1's binary_logloss: 0.240306\tvalid_1's auc: 0.77665\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7767  \u001b[0m | \u001b[0m 0.7307  \u001b[0m | \u001b[0m 497.6   \u001b[0m | \u001b[0m 7.704   \u001b[0m | \u001b[0m 43.93   \u001b[0m | \u001b[0m 49.29   \u001b[0m | \u001b[0m 62.3    \u001b[0m | \u001b[0m 2.761   \u001b[0m | \u001b[0m 6.593   \u001b[0m | \u001b[0m 0.7549  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.242137\ttraining's auc: 0.781639\tvalid_1's binary_logloss: 0.247503\tvalid_1's auc: 0.758526\n",
            "[200]\ttraining's binary_logloss: 0.23263\ttraining's auc: 0.805126\tvalid_1's binary_logloss: 0.243107\tvalid_1's auc: 0.768976\n",
            "[300]\ttraining's binary_logloss: 0.22657\ttraining's auc: 0.820635\tvalid_1's binary_logloss: 0.241573\tvalid_1's auc: 0.773201\n",
            "[400]\ttraining's binary_logloss: 0.222158\ttraining's auc: 0.832226\tvalid_1's binary_logloss: 0.240913\tvalid_1's auc: 0.775071\n",
            "[500]\ttraining's binary_logloss: 0.217876\ttraining's auc: 0.84362\tvalid_1's binary_logloss: 0.24046\tvalid_1's auc: 0.776496\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.217876\ttraining's auc: 0.84362\tvalid_1's binary_logloss: 0.24046\tvalid_1's auc: 0.776496\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7765  \u001b[0m | \u001b[0m 0.9702  \u001b[0m | \u001b[0m 490.2   \u001b[0m | \u001b[0m 6.676   \u001b[0m | \u001b[0m 130.6   \u001b[0m | \u001b[0m 1.011   \u001b[0m | \u001b[0m 62.38   \u001b[0m | \u001b[0m 1.419   \u001b[0m | \u001b[0m 0.3271  \u001b[0m | \u001b[0m 0.5556  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.244754\ttraining's auc: 0.776863\tvalid_1's binary_logloss: 0.248357\tvalid_1's auc: 0.758584\n",
            "[200]\ttraining's binary_logloss: 0.236514\ttraining's auc: 0.79531\tvalid_1's binary_logloss: 0.243758\tvalid_1's auc: 0.767616\n",
            "[300]\ttraining's binary_logloss: 0.231616\ttraining's auc: 0.807759\tvalid_1's binary_logloss: 0.241993\tvalid_1's auc: 0.772192\n",
            "[400]\ttraining's binary_logloss: 0.227928\ttraining's auc: 0.816863\tvalid_1's binary_logloss: 0.241086\tvalid_1's auc: 0.774506\n",
            "[500]\ttraining's binary_logloss: 0.224791\ttraining's auc: 0.824982\tvalid_1's binary_logloss: 0.240589\tvalid_1's auc: 0.775856\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.224791\ttraining's auc: 0.824982\tvalid_1's binary_logloss: 0.240589\tvalid_1's auc: 0.775856\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7759  \u001b[0m | \u001b[0m 0.594   \u001b[0m | \u001b[0m 493.5   \u001b[0m | \u001b[0m 6.165   \u001b[0m | \u001b[0m 26.6    \u001b[0m | \u001b[0m 1.477   \u001b[0m | \u001b[0m 60.15   \u001b[0m | \u001b[0m 4.686   \u001b[0m | \u001b[0m 2.352   \u001b[0m | \u001b[0m 0.9888  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.242193\ttraining's auc: 0.780768\tvalid_1's binary_logloss: 0.247238\tvalid_1's auc: 0.75918\n",
            "[200]\ttraining's binary_logloss: 0.23266\ttraining's auc: 0.803494\tvalid_1's binary_logloss: 0.242822\tvalid_1's auc: 0.769601\n",
            "[300]\ttraining's binary_logloss: 0.226701\ttraining's auc: 0.818631\tvalid_1's binary_logloss: 0.241548\tvalid_1's auc: 0.772958\n",
            "[400]\ttraining's binary_logloss: 0.22223\ttraining's auc: 0.830276\tvalid_1's binary_logloss: 0.240774\tvalid_1's auc: 0.775298\n",
            "[500]\ttraining's binary_logloss: 0.218401\ttraining's auc: 0.840332\tvalid_1's binary_logloss: 0.240327\tvalid_1's auc: 0.776645\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.218401\ttraining's auc: 0.840332\tvalid_1's binary_logloss: 0.240327\tvalid_1's auc: 0.776645\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7766  \u001b[0m | \u001b[0m 0.9335  \u001b[0m | \u001b[0m 495.5   \u001b[0m | \u001b[0m 9.276   \u001b[0m | \u001b[0m 21.97   \u001b[0m | \u001b[0m 43.59   \u001b[0m | \u001b[0m 63.13   \u001b[0m | \u001b[0m 0.3813  \u001b[0m | \u001b[0m 4.526   \u001b[0m | \u001b[0m 0.5504  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.24718\ttraining's auc: 0.763464\tvalid_1's binary_logloss: 0.249003\tvalid_1's auc: 0.75396\n",
            "[200]\ttraining's binary_logloss: 0.239976\ttraining's auc: 0.781626\tvalid_1's binary_logloss: 0.244136\tvalid_1's auc: 0.765987\n",
            "[300]\ttraining's binary_logloss: 0.235751\ttraining's auc: 0.7932\tvalid_1's binary_logloss: 0.242137\tvalid_1's auc: 0.771646\n",
            "[400]\ttraining's binary_logloss: 0.232543\ttraining's auc: 0.802154\tvalid_1's binary_logloss: 0.241049\tvalid_1's auc: 0.77476\n",
            "[500]\ttraining's binary_logloss: 0.230017\ttraining's auc: 0.809313\tvalid_1's binary_logloss: 0.240593\tvalid_1's auc: 0.775998\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.230017\ttraining's auc: 0.809313\tvalid_1's binary_logloss: 0.240593\tvalid_1's auc: 0.775998\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.776   \u001b[0m | \u001b[0m 0.861   \u001b[0m | \u001b[0m 492.5   \u001b[0m | \u001b[0m 12.7    \u001b[0m | \u001b[0m 15.12   \u001b[0m | \u001b[0m 1.937   \u001b[0m | \u001b[0m 27.72   \u001b[0m | \u001b[0m 1.034   \u001b[0m | \u001b[0m 8.386   \u001b[0m | \u001b[0m 0.6302  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.24348\ttraining's auc: 0.77895\tvalid_1's binary_logloss: 0.247784\tvalid_1's auc: 0.759417\n",
            "[200]\ttraining's binary_logloss: 0.234628\ttraining's auc: 0.798731\tvalid_1's binary_logloss: 0.243105\tvalid_1's auc: 0.76931\n",
            "[300]\ttraining's binary_logloss: 0.228824\ttraining's auc: 0.813704\tvalid_1's binary_logloss: 0.241488\tvalid_1's auc: 0.773618\n",
            "[400]\ttraining's binary_logloss: 0.223961\ttraining's auc: 0.826403\tvalid_1's binary_logloss: 0.240558\tvalid_1's auc: 0.776205\n",
            "[500]\ttraining's binary_logloss: 0.219667\ttraining's auc: 0.837626\tvalid_1's binary_logloss: 0.240092\tvalid_1's auc: 0.777397\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.219667\ttraining's auc: 0.837626\tvalid_1's binary_logloss: 0.240092\tvalid_1's auc: 0.777397\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7774  \u001b[0m | \u001b[0m 0.6638  \u001b[0m | \u001b[0m 478.1   \u001b[0m | \u001b[0m 14.14   \u001b[0m | \u001b[0m 19.42   \u001b[0m | \u001b[0m 47.59   \u001b[0m | \u001b[0m 62.23   \u001b[0m | \u001b[0m 7.326   \u001b[0m | \u001b[0m 5.152   \u001b[0m | \u001b[0m 0.8538  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.242371\ttraining's auc: 0.781128\tvalid_1's binary_logloss: 0.247334\tvalid_1's auc: 0.7596\n",
            "[200]\ttraining's binary_logloss: 0.232679\ttraining's auc: 0.803663\tvalid_1's binary_logloss: 0.242723\tvalid_1's auc: 0.769873\n",
            "[300]\ttraining's binary_logloss: 0.226208\ttraining's auc: 0.820325\tvalid_1's binary_logloss: 0.241241\tvalid_1's auc: 0.773856\n",
            "[400]\ttraining's binary_logloss: 0.220801\ttraining's auc: 0.834453\tvalid_1's binary_logloss: 0.240458\tvalid_1's auc: 0.776126\n",
            "[500]\ttraining's binary_logloss: 0.216217\ttraining's auc: 0.846246\tvalid_1's binary_logloss: 0.240081\tvalid_1's auc: 0.777123\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.216217\ttraining's auc: 0.846246\tvalid_1's binary_logloss: 0.240081\tvalid_1's auc: 0.777123\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7771  \u001b[0m | \u001b[0m 0.7899  \u001b[0m | \u001b[0m 451.0   \u001b[0m | \u001b[0m 14.17   \u001b[0m | \u001b[0m 16.47   \u001b[0m | \u001b[0m 48.3    \u001b[0m | \u001b[0m 62.66   \u001b[0m | \u001b[0m 0.8003  \u001b[0m | \u001b[0m 5.522   \u001b[0m | \u001b[0m 0.5739  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243874\ttraining's auc: 0.778882\tvalid_1's binary_logloss: 0.248008\tvalid_1's auc: 0.759313\n",
            "[200]\ttraining's binary_logloss: 0.23524\ttraining's auc: 0.798016\tvalid_1's binary_logloss: 0.243316\tvalid_1's auc: 0.768777\n",
            "[300]\ttraining's binary_logloss: 0.230093\ttraining's auc: 0.811013\tvalid_1's binary_logloss: 0.241679\tvalid_1's auc: 0.773045\n",
            "[400]\ttraining's binary_logloss: 0.226176\ttraining's auc: 0.820855\tvalid_1's binary_logloss: 0.240876\tvalid_1's auc: 0.775129\n",
            "[500]\ttraining's binary_logloss: 0.222776\ttraining's auc: 0.829652\tvalid_1's binary_logloss: 0.240353\tvalid_1's auc: 0.776519\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.222776\ttraining's auc: 0.829652\tvalid_1's binary_logloss: 0.240353\tvalid_1's auc: 0.776519\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7765  \u001b[0m | \u001b[0m 0.6147  \u001b[0m | \u001b[0m 485.7   \u001b[0m | \u001b[0m 7.26    \u001b[0m | \u001b[0m 19.26   \u001b[0m | \u001b[0m 5.714   \u001b[0m | \u001b[0m 60.35   \u001b[0m | \u001b[0m 2.702   \u001b[0m | \u001b[0m 9.9     \u001b[0m | \u001b[0m 0.6904  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.24498\ttraining's auc: 0.77289\tvalid_1's binary_logloss: 0.248164\tvalid_1's auc: 0.757677\n",
            "[200]\ttraining's binary_logloss: 0.236659\ttraining's auc: 0.792195\tvalid_1's binary_logloss: 0.2433\tvalid_1's auc: 0.768396\n",
            "[300]\ttraining's binary_logloss: 0.231583\ttraining's auc: 0.805419\tvalid_1's binary_logloss: 0.241604\tvalid_1's auc: 0.772935\n",
            "[400]\ttraining's binary_logloss: 0.22748\ttraining's auc: 0.816337\tvalid_1's binary_logloss: 0.240637\tvalid_1's auc: 0.775689\n",
            "[500]\ttraining's binary_logloss: 0.224103\ttraining's auc: 0.825461\tvalid_1's binary_logloss: 0.240223\tvalid_1's auc: 0.776814\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.224103\ttraining's auc: 0.825461\tvalid_1's binary_logloss: 0.240223\tvalid_1's auc: 0.776814\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7768  \u001b[0m | \u001b[0m 0.7049  \u001b[0m | \u001b[0m 484.8   \u001b[0m | \u001b[0m 10.56   \u001b[0m | \u001b[0m 13.1    \u001b[0m | \u001b[0m 48.91   \u001b[0m | \u001b[0m 43.8    \u001b[0m | \u001b[0m 0.5117  \u001b[0m | \u001b[0m 9.967   \u001b[0m | \u001b[0m 0.7057  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.245158\ttraining's auc: 0.770998\tvalid_1's binary_logloss: 0.248275\tvalid_1's auc: 0.757085\n",
            "[200]\ttraining's binary_logloss: 0.23683\ttraining's auc: 0.791679\tvalid_1's binary_logloss: 0.243534\tvalid_1's auc: 0.767821\n",
            "[300]\ttraining's binary_logloss: 0.231488\ttraining's auc: 0.806403\tvalid_1's binary_logloss: 0.241821\tvalid_1's auc: 0.772479\n",
            "[400]\ttraining's binary_logloss: 0.227132\ttraining's auc: 0.818757\tvalid_1's binary_logloss: 0.240942\tvalid_1's auc: 0.77485\n",
            "[500]\ttraining's binary_logloss: 0.223328\ttraining's auc: 0.830021\tvalid_1's binary_logloss: 0.2406\tvalid_1's auc: 0.77589\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.223328\ttraining's auc: 0.830021\tvalid_1's binary_logloss: 0.2406\tvalid_1's auc: 0.77589\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7759  \u001b[0m | \u001b[0m 0.6788  \u001b[0m | \u001b[0m 499.1   \u001b[0m | \u001b[0m 9.791   \u001b[0m | \u001b[0m 12.04   \u001b[0m | \u001b[0m 1.209   \u001b[0m | \u001b[0m 37.5    \u001b[0m | \u001b[0m 1.511   \u001b[0m | \u001b[0m 0.2041  \u001b[0m | \u001b[0m 0.5108  \u001b[0m |\n",
            "=====================================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsEIaNgMDlOV"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "## Save pickle\r\n",
        "with open(\"/content/lgbBO.pickle\",\"wb\") as fw:\r\n",
        "    pickle.dump(lgbBO, fw)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L3qCmiXvR5a"
      },
      "source": [
        "##### Iteration 수행 결과 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DinJ-PaxvR5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d599c4b4-9f86-4745-e2f8-b07e36881d1a"
      },
      "source": [
        "# BayesianOptimization객체의 res는 iteration 수행 시마다 모든 함수 반환결과와 그때의 파라미터 결과값을 가지고 있음. \n",
        "# 이러한 추론값을 lgb_roc_eval()에 넣는다.\n",
        "lgbBO.res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'params': {'colsample_bytree': 0.7744067519636624,\n",
              "   'max_bin': 360.44278952248555,\n",
              "   'max_depth': 12.027633760716439,\n",
              "   'min_child_samples': 113.52780476941041,\n",
              "   'min_child_weight': 21.75908516760633,\n",
              "   'num_leaves': 49.835764522666246,\n",
              "   'reg_alpha': 21.884984691022,\n",
              "   'reg_lambda': 8.917838234820016,\n",
              "   'subsample': 0.9818313802505146},\n",
              "  'target': 0.7754739702428558},\n",
              " {'params': {'colsample_bytree': 0.6917207594128889,\n",
              "   'max_bin': 397.94526866050563,\n",
              "   'max_depth': 11.288949197529044,\n",
              "   'min_child_samples': 117.92846660784714,\n",
              "   'min_child_weight': 46.35423527634039,\n",
              "   'num_leaves': 26.841442327915477,\n",
              "   'reg_alpha': 4.36559369208002,\n",
              "   'reg_lambda': 0.20316375600581688,\n",
              "   'subsample': 0.916309922773969},\n",
              "  'target': 0.7753573432834208},\n",
              " {'params': {'colsample_bytree': 0.8890783754749252,\n",
              "   'max_bin': 436.30595264094137,\n",
              "   'max_depth': 15.78618342232764,\n",
              "   'min_child_samples': 161.8401272011775,\n",
              "   'min_child_weight': 23.61248875039366,\n",
              "   'num_leaves': 55.22116705145822,\n",
              "   'reg_alpha': 5.922538549187972,\n",
              "   'reg_lambda': 6.3995702922539115,\n",
              "   'subsample': 0.5716766437045232},\n",
              "  'target': 0.7773320021744632},\n",
              " {'params': {'colsample_bytree': 0.972334458524792,\n",
              "   'max_bin': 265.70567765753515,\n",
              "   'max_depth': 10.146619399905235,\n",
              "   'min_child_samples': 60.265566299879126,\n",
              "   'min_child_weight': 38.93745078227661,\n",
              "   'num_leaves': 42.24601328866194,\n",
              "   'reg_alpha': 28.426013103943742,\n",
              "   'reg_lambda': 0.18887921456311507,\n",
              "   'subsample': 0.8088177485379385},\n",
              "  'target': 0.7749940765618106},\n",
              " {'params': {'colsample_bytree': 0.8060478613612108,\n",
              "   'max_bin': 312.2976584686309,\n",
              "   'max_depth': 15.437480785146242,\n",
              "   'min_child_samples': 139.54585682966186,\n",
              "   'min_child_weight': 18.615887128115514,\n",
              "   'num_leaves': 41.481278151973655,\n",
              "   'reg_alpha': 34.88458348440397,\n",
              "   'reg_lambda': 0.6031944908210691,\n",
              "   'subsample': 0.8333833577228338},\n",
              "  'target': 0.7741980660329925},\n",
              " {'params': {'colsample_bytree': 0.8538298637688885,\n",
              "   'max_bin': 499.18172097104025,\n",
              "   'max_depth': 7.1187205183646585,\n",
              "   'min_child_samples': 10.40382501514027,\n",
              "   'min_child_weight': 37.64143876594502,\n",
              "   'num_leaves': 46.751076731952274,\n",
              "   'reg_alpha': 34.54679765680322,\n",
              "   'reg_lambda': 7.535496823229152,\n",
              "   'subsample': 0.7467532758879181},\n",
              "  'target': 0.7743139273609485},\n",
              " {'params': {'colsample_bytree': 0.9750941359511892,\n",
              "   'max_bin': 12.501359452451002,\n",
              "   'max_depth': 15.865587065065188,\n",
              "   'min_child_samples': 199.06043810748636,\n",
              "   'min_child_weight': 43.32982582556308,\n",
              "   'num_leaves': 53.78170583679077,\n",
              "   'reg_alpha': 14.984214461767769,\n",
              "   'reg_lambda': 9.60963231580962,\n",
              "   'subsample': 0.7368099967377815},\n",
              "  'target': 0.7720062711953142},\n",
              " {'params': {'colsample_bytree': 0.5606964411191951,\n",
              "   'max_bin': 497.7454412199526,\n",
              "   'max_depth': 7.087272483457448,\n",
              "   'min_child_samples': 199.5175802035777,\n",
              "   'min_child_weight': 48.53382598339578,\n",
              "   'num_leaves': 46.57200227776936,\n",
              "   'reg_alpha': 8.795600579406749,\n",
              "   'reg_lambda': 5.27619358756324,\n",
              "   'subsample': 0.8411371145522544},\n",
              "  'target': 0.7756544353008543},\n",
              " {'params': {'colsample_bytree': 0.9722063900233824,\n",
              "   'max_bin': 497.82308500508594,\n",
              "   'max_depth': 15.758325685837493,\n",
              "   'min_child_samples': 197.60491797740553,\n",
              "   'min_child_weight': 4.999554027770358,\n",
              "   'num_leaves': 32.35325045820552,\n",
              "   'reg_alpha': 43.15240531167431,\n",
              "   'reg_lambda': 0.16547147713489843,\n",
              "   'subsample': 0.6482851764642698},\n",
              "  'target': 0.7727560197921964},\n",
              " {'params': {'colsample_bytree': 0.5342232406645204,\n",
              "   'max_bin': 489.86665132276073,\n",
              "   'max_depth': 8.997688603000276,\n",
              "   'min_child_samples': 10.210966478486121,\n",
              "   'min_child_weight': 39.73455999523621,\n",
              "   'num_leaves': 36.507079883778296,\n",
              "   'reg_alpha': 1.808669646029281,\n",
              "   'reg_lambda': 5.03958878713407,\n",
              "   'subsample': 0.5382652171575891},\n",
              "  'target': 0.7764914515903136},\n",
              " {'params': {'colsample_bytree': 0.6871924599882824,\n",
              "   'max_bin': 479.6386373823657,\n",
              "   'max_depth': 10.234811669618706,\n",
              "   'min_child_samples': 24.871920387237736,\n",
              "   'min_child_weight': 6.990018287895288,\n",
              "   'num_leaves': 60.103948656421274,\n",
              "   'reg_alpha': 0.8071247513752541,\n",
              "   'reg_lambda': 5.776756371548493,\n",
              "   'subsample': 0.7786645674657318},\n",
              "  'target': 0.7768626430742653},\n",
              " {'params': {'colsample_bytree': 0.687432080723539,\n",
              "   'max_bin': 479.5790809130459,\n",
              "   'max_depth': 15.624247892861597,\n",
              "   'min_child_samples': 15.727227480527613,\n",
              "   'min_child_weight': 46.015612690004126,\n",
              "   'num_leaves': 60.62355316972579,\n",
              "   'reg_alpha': 0.6880799034091644,\n",
              "   'reg_lambda': 2.141966980555839,\n",
              "   'subsample': 0.9412841359789756},\n",
              "  'target': 0.777577672983937},\n",
              " {'params': {'colsample_bytree': 0.955778913998498,\n",
              "   'max_bin': 493.24533086499315,\n",
              "   'max_depth': 15.267484348764935,\n",
              "   'min_child_samples': 18.245751562382765,\n",
              "   'min_child_weight': 40.870752907958405,\n",
              "   'num_leaves': 55.505857378740615,\n",
              "   'reg_alpha': 0.43710361190113756,\n",
              "   'reg_lambda': 1.3483530217402222,\n",
              "   'subsample': 0.9352585984365811},\n",
              "  'target': 0.7769813334264206},\n",
              " {'params': {'colsample_bytree': 0.6557051331388017,\n",
              "   'max_bin': 489.8934216857914,\n",
              "   'max_depth': 10.31143629269451,\n",
              "   'min_child_samples': 17.81696518957149,\n",
              "   'min_child_weight': 1.0494732128777182,\n",
              "   'num_leaves': 37.80201876050929,\n",
              "   'reg_alpha': 1.6854128477794645,\n",
              "   'reg_lambda': 1.6410327033509082,\n",
              "   'subsample': 0.5973767065010218},\n",
              "  'target': 0.7762975625662807},\n",
              " {'params': {'colsample_bytree': 0.5837978592082946,\n",
              "   'max_bin': 478.06947661959055,\n",
              "   'max_depth': 15.331072812311916,\n",
              "   'min_child_samples': 16.944932284758288,\n",
              "   'min_child_weight': 43.66259945159295,\n",
              "   'num_leaves': 58.10308105931011,\n",
              "   'reg_alpha': 1.8732768087453089,\n",
              "   'reg_lambda': 6.925846042954574,\n",
              "   'subsample': 0.8210062735198591},\n",
              "  'target': 0.7774589032094291},\n",
              " {'params': {'colsample_bytree': 0.878984166735569,\n",
              "   'max_bin': 487.319455209816,\n",
              "   'max_depth': 13.74347971689194,\n",
              "   'min_child_samples': 22.793854301098456,\n",
              "   'min_child_weight': 47.051313468761144,\n",
              "   'num_leaves': 63.32449765350978,\n",
              "   'reg_alpha': 1.131005525995249,\n",
              "   'reg_lambda': 9.356034325036058,\n",
              "   'subsample': 0.8717664011361355},\n",
              "  'target': 0.7771821464911522},\n",
              " {'params': {'colsample_bytree': 0.7436762853652641,\n",
              "   'max_bin': 494.6519941194128,\n",
              "   'max_depth': 14.273550154831288,\n",
              "   'min_child_samples': 25.784295891426886,\n",
              "   'min_child_weight': 2.6913774511864754,\n",
              "   'num_leaves': 57.965834800533756,\n",
              "   'reg_alpha': 2.4699153309230764,\n",
              "   'reg_lambda': 9.797178761741076,\n",
              "   'subsample': 0.5823503102854222},\n",
              "  'target': 0.7780482186540827},\n",
              " {'params': {'colsample_bytree': 0.6974622852743844,\n",
              "   'max_bin': 467.4711221671223,\n",
              "   'max_depth': 10.230484948219582,\n",
              "   'min_child_samples': 22.574247463399168,\n",
              "   'min_child_weight': 3.60739558479408,\n",
              "   'num_leaves': 62.53317443276672,\n",
              "   'reg_alpha': 5.255418817283818,\n",
              "   'reg_lambda': 8.661520568805088,\n",
              "   'subsample': 0.7035580471149167},\n",
              "  'target': 0.7777908139862375},\n",
              " {'params': {'colsample_bytree': 0.5437407286308563,\n",
              "   'max_bin': 488.3548304818276,\n",
              "   'max_depth': 10.285653018830278,\n",
              "   'min_child_samples': 45.29162859948177,\n",
              "   'min_child_weight': 1.8189456648868672,\n",
              "   'num_leaves': 62.43189084803863,\n",
              "   'reg_alpha': 3.4190610024000705,\n",
              "   'reg_lambda': 9.01873010403026,\n",
              "   'subsample': 0.6595375490385381},\n",
              "  'target': 0.7779424074306232},\n",
              " {'params': {'colsample_bytree': 0.7745130300822609,\n",
              "   'max_bin': 488.68846826819686,\n",
              "   'max_depth': 6.037461418571719,\n",
              "   'min_child_samples': 34.4169937605701,\n",
              "   'min_child_weight': 5.833403026794266,\n",
              "   'num_leaves': 60.80651810352303,\n",
              "   'reg_alpha': 7.307667210692115,\n",
              "   'reg_lambda': 0.9877307504431427,\n",
              "   'subsample': 0.5465779714003538},\n",
              "  'target': 0.7755680269581322},\n",
              " {'params': {'colsample_bytree': 0.7306833224982413,\n",
              "   'max_bin': 497.6429483962119,\n",
              "   'max_depth': 7.703617399780626,\n",
              "   'min_child_samples': 43.933314820516514,\n",
              "   'min_child_weight': 49.292873668988236,\n",
              "   'num_leaves': 62.29738922363282,\n",
              "   'reg_alpha': 2.760930627922642,\n",
              "   'reg_lambda': 6.592754587746761,\n",
              "   'subsample': 0.7548714507500771},\n",
              "  'target': 0.7766501692197265},\n",
              " {'params': {'colsample_bytree': 0.9702051409369551,\n",
              "   'max_bin': 490.2468911528458,\n",
              "   'max_depth': 6.675646963122917,\n",
              "   'min_child_samples': 130.59760265574238,\n",
              "   'min_child_weight': 1.0107380385879603,\n",
              "   'num_leaves': 62.37894582515848,\n",
              "   'reg_alpha': 1.419040898790039,\n",
              "   'reg_lambda': 0.32710686177754544,\n",
              "   'subsample': 0.5555631966642643},\n",
              "  'target': 0.7764958579424354},\n",
              " {'params': {'colsample_bytree': 0.5939730226596387,\n",
              "   'max_bin': 493.4939994485024,\n",
              "   'max_depth': 6.165368640539341,\n",
              "   'min_child_samples': 26.597526415005788,\n",
              "   'min_child_weight': 1.4766355056497291,\n",
              "   'num_leaves': 60.14844685457922,\n",
              "   'reg_alpha': 4.686393994145287,\n",
              "   'reg_lambda': 2.3517785307956647,\n",
              "   'subsample': 0.988798782614232},\n",
              "  'target': 0.7758560235277473},\n",
              " {'params': {'colsample_bytree': 0.9335178880792802,\n",
              "   'max_bin': 495.4705853959828,\n",
              "   'max_depth': 9.275577008280285,\n",
              "   'min_child_samples': 21.97422388511532,\n",
              "   'min_child_weight': 43.58541175677125,\n",
              "   'num_leaves': 63.128263229486635,\n",
              "   'reg_alpha': 0.3813229629049955,\n",
              "   'reg_lambda': 4.526261020784162,\n",
              "   'subsample': 0.5503847974222735},\n",
              "  'target': 0.7766452895103834},\n",
              " {'params': {'colsample_bytree': 0.8609688575892369,\n",
              "   'max_bin': 492.5130460857743,\n",
              "   'max_depth': 12.704233001329275,\n",
              "   'min_child_samples': 15.12064118686286,\n",
              "   'min_child_weight': 1.937108403750006,\n",
              "   'num_leaves': 27.717729763522392,\n",
              "   'reg_alpha': 1.0344979663831602,\n",
              "   'reg_lambda': 8.386183291300387,\n",
              "   'subsample': 0.6301564507620973},\n",
              "  'target': 0.7759978146653764},\n",
              " {'params': {'colsample_bytree': 0.6637581182039965,\n",
              "   'max_bin': 478.1043158687786,\n",
              "   'max_depth': 14.143838192928582,\n",
              "   'min_child_samples': 19.416823523968596,\n",
              "   'min_child_weight': 47.588246099984744,\n",
              "   'num_leaves': 62.23191279604004,\n",
              "   'reg_alpha': 7.325958014492767,\n",
              "   'reg_lambda': 5.151845619559748,\n",
              "   'subsample': 0.8538381398189729},\n",
              "  'target': 0.7773965376012826},\n",
              " {'params': {'colsample_bytree': 0.7899081844055998,\n",
              "   'max_bin': 451.0489642863229,\n",
              "   'max_depth': 14.166461630530417,\n",
              "   'min_child_samples': 16.4694838865052,\n",
              "   'min_child_weight': 48.29924042617962,\n",
              "   'num_leaves': 62.66005194793132,\n",
              "   'reg_alpha': 0.8003075082970005,\n",
              "   'reg_lambda': 5.521570856635001,\n",
              "   'subsample': 0.5739446148147153},\n",
              "  'target': 0.7771233405928487},\n",
              " {'params': {'colsample_bytree': 0.6146526165857328,\n",
              "   'max_bin': 485.66445905580105,\n",
              "   'max_depth': 7.259950461855689,\n",
              "   'min_child_samples': 19.264095092455467,\n",
              "   'min_child_weight': 5.714188025170126,\n",
              "   'num_leaves': 60.354986335797236,\n",
              "   'reg_alpha': 2.7024242768304942,\n",
              "   'reg_lambda': 9.90021113905228,\n",
              "   'subsample': 0.6903840702052592},\n",
              "  'target': 0.7765192494137196},\n",
              " {'params': {'colsample_bytree': 0.7048968334628858,\n",
              "   'max_bin': 484.82472602615434,\n",
              "   'max_depth': 10.55974479883751,\n",
              "   'min_child_samples': 13.095052894611987,\n",
              "   'min_child_weight': 48.907808701184535,\n",
              "   'num_leaves': 43.80076300813039,\n",
              "   'reg_alpha': 0.5116783103676071,\n",
              "   'reg_lambda': 9.966798515319228,\n",
              "   'subsample': 0.7057371801704698},\n",
              "  'target': 0.7768137856198469},\n",
              " {'params': {'colsample_bytree': 0.6787973056586718,\n",
              "   'max_bin': 499.12451398147346,\n",
              "   'max_depth': 9.791393974727306,\n",
              "   'min_child_samples': 12.04307994116352,\n",
              "   'min_child_weight': 1.2092535299513751,\n",
              "   'num_leaves': 37.50084251381196,\n",
              "   'reg_alpha': 1.511103192515003,\n",
              "   'reg_lambda': 0.2041043723043457,\n",
              "   'subsample': 0.5107804152361152},\n",
              "  'target': 0.775890440410018}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pF714uFvR5l"
      },
      "source": [
        "##### Iteration 결과 Dictionary에서 최대 target값을 가지는 index 추출하고 그때의 parameter 값을 추출.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR-_KsyivR5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69e13a66-3842-4621-b179-a88b716895da"
      },
      "source": [
        "# dictionary에 있는 target값을 모두 추출\n",
        "target_list = []\n",
        "for result in lgbBO.res:\n",
        "    target = result['target']\n",
        "    target_list.append(target)\n",
        "print(target_list)\n",
        "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
        "print('maximum target index:', np.argmax(np.array(target_list)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.7754739702428558, 0.7753573432834208, 0.7773320021744632, 0.7749940765618106, 0.7741980660329925, 0.7743139273609485, 0.7720062711953142, 0.7756544353008543, 0.7727560197921964, 0.7764914515903136, 0.7768626430742653, 0.777577672983937, 0.7769813334264206, 0.7762975625662807, 0.7774589032094291, 0.7771821464911522, 0.7780482186540827, 0.7777908139862375, 0.7779424074306232, 0.7755680269581322, 0.7766501692197265, 0.7764958579424354, 0.7758560235277473, 0.7766452895103834, 0.7759978146653764, 0.7773965376012826, 0.7771233405928487, 0.7765192494137196, 0.7768137856198469, 0.775890440410018]\n",
            "maximum target index: 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZLxoImyvR5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc69cc4c-615c-4cd1-bda5-90f6d682ba52"
      },
      "source": [
        "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
        "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
        "print(max_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'target': 0.7780482186540827, 'params': {'colsample_bytree': 0.7436762853652641, 'max_bin': 494.6519941194128, 'max_depth': 14.273550154831288, 'min_child_samples': 25.784295891426886, 'min_child_weight': 2.6913774511864754, 'num_leaves': 57.965834800533756, 'reg_alpha': 2.4699153309230764, 'reg_lambda': 9.797178761741076, 'subsample': 0.5823503102854222}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ0EHnuIvR53"
      },
      "source": [
        "##### 최적화된 하이퍼 파라미터를 기반으로 재 테스트 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32l2G2bZvR54"
      },
      "source": [
        "def train_apps_all(apps_all_train):\n",
        "    ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
        "    target_app = apps_all_train['TARGET']\n",
        "\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(ftr_app, target_app, test_size=0.3, random_state=2020)\n",
        "    print('train shape:', train_x.shape, 'valid shape:', valid_x.shape)\n",
        "    clf = LGBMClassifier(\n",
        "                nthread=4,\n",
        "                n_estimators=1000,\n",
        "                learning_rate=0.02,\n",
        "                max_depth = 14,\n",
        "                num_leaves=58,\n",
        "                colsample_bytree=0.743,\n",
        "                subsample=0.5823,\n",
        "                max_bin=494,\n",
        "                reg_alpha=2.469,\n",
        "                reg_lambda=9.797,\n",
        "                min_child_weight=3,\n",
        "                min_child_samples=25,\n",
        "                silent=-1,\n",
        "                verbose=-1,\n",
        "                )\n",
        "\n",
        "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 100, \n",
        "                early_stopping_rounds= 100)\n",
        "    \n",
        "    return clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxqV8KpFvR5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b69ca981-f64c-4223-f8f2-c8aab29d1129"
      },
      "source": [
        "apps_all = get_apps_all_with_prev_agg(apps, prev)\n",
        "apps_all = get_apps_all_encoded(apps_all)\n",
        "apps_all_train, apps_all_test = get_apps_all_train_test(apps_all)\n",
        "clf = train_apps_all(apps_all_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prev_agg shape: (338857, 41)\n",
            "apps_all before merge shape: (356255, 135)\n",
            "apps_all after merge with prev_agg shape: (356255, 176)\n",
            "train shape: (215257, 174) valid shape: (92254, 174)\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243273\ttraining's auc: 0.778365\tvalid_1's binary_logloss: 0.247732\tvalid_1's auc: 0.758959\n",
            "[200]\ttraining's binary_logloss: 0.234034\ttraining's auc: 0.80006\tvalid_1's binary_logloss: 0.242988\tvalid_1's auc: 0.769532\n",
            "[300]\ttraining's binary_logloss: 0.227911\ttraining's auc: 0.816094\tvalid_1's binary_logloss: 0.241308\tvalid_1's auc: 0.774188\n",
            "[400]\ttraining's binary_logloss: 0.22284\ttraining's auc: 0.829543\tvalid_1's binary_logloss: 0.240419\tvalid_1's auc: 0.776602\n",
            "[500]\ttraining's binary_logloss: 0.218553\ttraining's auc: 0.840915\tvalid_1's binary_logloss: 0.240045\tvalid_1's auc: 0.777541\n",
            "[600]\ttraining's binary_logloss: 0.214765\ttraining's auc: 0.850734\tvalid_1's binary_logloss: 0.239893\tvalid_1's auc: 0.777986\n",
            "[700]\ttraining's binary_logloss: 0.211239\ttraining's auc: 0.859756\tvalid_1's binary_logloss: 0.239799\tvalid_1's auc: 0.778285\n",
            "[800]\ttraining's binary_logloss: 0.207942\ttraining's auc: 0.867864\tvalid_1's binary_logloss: 0.239712\tvalid_1's auc: 0.778555\n",
            "[900]\ttraining's binary_logloss: 0.204707\ttraining's auc: 0.875579\tvalid_1's binary_logloss: 0.239619\tvalid_1's auc: 0.778832\n",
            "[1000]\ttraining's binary_logloss: 0.201701\ttraining's auc: 0.882725\tvalid_1's binary_logloss: 0.239637\tvalid_1's auc: 0.77876\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.201701\ttraining's auc: 0.882725\tvalid_1's binary_logloss: 0.239637\tvalid_1's auc: 0.77876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQrAcQ1QvR6I"
      },
      "source": [
        "preds = clf.predict_proba(apps_all_test.drop('SK_ID_CURR', axis=1))[:, 1 ]\n",
        "apps_all_test['TARGET'] = preds\n",
        "# SK_ID_CURR과 TARGET 값만 csv 형태로 생성. 코랩 버전은 구글 드라이브 절대 경로로 입력  \n",
        "# default_dir = \"/content/gdrive/My Drive\"\n",
        "default_dir = \"/content\"\n",
        "apps_all_test[['SK_ID_CURR', 'TARGET']].to_csv(os.path.join(default_dir,'prev_baseline_BO_tuning_01.csv'), index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l01RNW9nvR6y"
      },
      "source": [
        "#### cross validation 으로 hyper parameter 재 tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_g8dD9U_ZYI"
      },
      "source": [
        "cross validation 으로하면 train에 과적합을 막아주지만     \r\n",
        "꼭 그게 나은 성능을 보장해 주는 것은 아니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF-ISZ9fiGXm"
      },
      "source": [
        "# 조금씩 변수 이름이 다르다\n",
        "bayesian_params = {\n",
        "    'max_depth': (6, 16), \n",
        "    'num_leaves': (24, 64), \n",
        "    'min_data_in_leaf': (10, 200), # min_child_samples\n",
        "    'min_child_weight':(1, 50),\n",
        "    'bagging_fraction':(0.5, 1.0), # subsample\n",
        "    'feature_fraction': (0.5, 1.0), # colsample_bytree\n",
        "    'max_bin':(10, 500),\n",
        "    'lambda_l2':(0.001, 10), # reg_lambda\n",
        "    'lambda_l1': (0.01, 50) # reg_alpha\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1XnADhsiGXm"
      },
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "train_data = lgb.Dataset(data=ftr_app, label=target_app, free_raw_data=False)\n",
        "def lgb_roc_eval_cv(max_depth, num_leaves, min_data_in_leaf, min_child_weight, bagging_fraction, \n",
        "                 feature_fraction,  max_bin, lambda_l2, lambda_l1):   \n",
        "    # python wrapper여서 변수이름이 조금다름\n",
        "    params = {\n",
        "        \"num_iterations\":500, \"learning_rate\":0.02,\n",
        "        'early_stopping_rounds':100, 'metric':'auc',\n",
        "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 실수형 하이퍼 파라미터는 정수형으로 변경 \n",
        "        'num_leaves': int(round(num_leaves)), \n",
        "        'min_data_in_leaf': int(round(min_data_in_leaf)),\n",
        "        'min_child_weight': int(round(min_child_weight)),\n",
        "        'bagging_fraction': max(min(bagging_fraction, 1), 0), \n",
        "        'feature_fraction': max(min(feature_fraction, 1), 0),\n",
        "        'max_bin':  max(int(round(max_bin)),10),\n",
        "        'lambda_l2': max(lambda_l2,0),\n",
        "        'lambda_l1': max(lambda_l1, 0)\n",
        "    }\n",
        "    # 파이썬 lightgbm의 cv 메소드를 사용. \n",
        "    \n",
        "    cv_result = lgb.cv(params, train_data, nfold=3, seed=0,  verbose_eval =100,  early_stopping_rounds=50, metrics=['auc'])\n",
        "    return max(cv_result['auc-mean'])   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68pfjZqKiGXm"
      },
      "source": [
        "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
        "print(max_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRmHoobeiGXm"
      },
      "source": [
        "def train_apps_all(apps_all_train):\n",
        "    ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
        "    target_app = apps_all_train['TARGET']\n",
        "\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(ftr_app, target_app, test_size=0.3, random_state=2020)\n",
        "    print('train shape:', train_x.shape, 'valid shape:', valid_x.shape)\n",
        "    clf = LGBMClassifier(\n",
        "                nthread=4,\n",
        "                n_estimators=1000,\n",
        "                learning_rate=0.02,\n",
        "                max_depth = 10,\n",
        "                num_leaves=60,\n",
        "                colsample_bytree=0.511,\n",
        "                subsample=0.785,\n",
        "                max_bin=208,\n",
        "                reg_alpha=7.009,\n",
        "                reg_lambda=6.579,\n",
        "                min_child_weight=40,\n",
        "                min_child_samples=91,\n",
        "                silent=-1,\n",
        "                verbose=-1,\n",
        "                )\n",
        "\n",
        "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 100, \n",
        "                early_stopping_rounds= 100)\n",
        "    \n",
        "    return clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTkR5eUmiGXm"
      },
      "source": [
        "apps_all = get_apps_all_with_prev_agg(apps, prev)\n",
        "apps_all = get_apps_all_encoded(apps_all)\n",
        "apps_all_train, apps_all_test = get_apps_all_train_test(apps_all)\n",
        "clf = train_apps_all(apps_all_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KXhgXm6iGXn"
      },
      "source": [
        "preds = clf.predict_proba(apps_all_test.drop('SK_ID_CURR', axis=1))[:, 1 ]\n",
        "apps_all_test['TARGET'] = preds\n",
        "# SK_ID_CURR과 TARGET 값만 csv 형태로 생성. 코랩 버전은 구글 드라이브 절대 경로로 입력  \n",
        "default_dir = \"/content/gdrive/My Drive\"\n",
        "app_test[['SK_ID_CURR', 'TARGET']].to_csv(os.path.join(default_dir,'prev_baseline_tuning_02.csv'), index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}